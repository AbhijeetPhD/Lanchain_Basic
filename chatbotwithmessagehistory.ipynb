{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"]=os.environ.get(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"Gemma2-9b-It\",temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! ðŸ‘‹  How can I help you today? ðŸ˜Š\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 12, 'total_tokens': 27, 'completion_time': 0.027272727, 'prompt_time': 0.001939647, 'queue_time': 0.234798962, 'total_time': 0.029212374}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-fa8b2537-8c2f-44ec-9e8c-7d1204f939dd-0', usage_metadata={'input_tokens': 12, 'output_tokens': 15, 'total_tokens': 27})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"hi, there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\n\\n</think>\\n\\nHi! I'm DeepSeek-R1, an artificial intelligence assistant created by DeepSeek. I'm at your service and would be delighted to assist you with any inquiries or tasks you may have.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 44, 'prompt_tokens': 8, 'total_tokens': 52, 'completion_time': 0.314285714, 'prompt_time': 0.002973152, 'queue_time': 0.056705527, 'total_time': 0.317258866}, 'model_name': 'deepseek-r1-distill-qwen-32b', 'system_fingerprint': 'fp_0852292947', 'finish_reason': 'stop', 'logprobs': None}, id='run-3555de2a-a7ad-40f6-a4a4-ab9113081801-0', usage_metadata={'input_tokens': 8, 'output_tokens': 44, 'total_tokens': 52})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke([HumanMessage(content=\"hi,who are you?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_prompt=(\n",
    "    [HumanMessage(content=\"hi, i am Abhijeet\"),\n",
    "                AIMessage(content=\"Hey, There how are you doing\"),\n",
    "                HumanMessage(content=\"I'm doing well. How about you?\"),\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hi, i am Abhijeet', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Hey, There how are you doing', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"I'm doing well. How about you?\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, so the user just said, \"I\\'m doing well. How about you?\" I need to respond in a friendly and positive way. I should acknowledge their good news and then share that I\\'m doing well too. Maybe add something about being here to help to keep the conversation going. I should keep it simple and conversational, not too formal. Let me put that together.\\n</think>\\n\\nI\\'m doing well too, thank you! I\\'m here to help with whatever you need. How can I assist you today?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 109, 'prompt_tokens': 29, 'total_tokens': 138, 'completion_time': 0.778571429, 'prompt_time': 0.003910326, 'queue_time': 0.051776244, 'total_time': 0.782481755}, 'model_name': 'deepseek-r1-distill-qwen-32b', 'system_fingerprint': 'fp_d458a8aba5', 'finish_reason': 'stop', 'logprobs': None}, id='run-628b585e-35da-43f8-aa70-c78b40c8ed92-0', usage_metadata={'input_tokens': 29, 'output_tokens': 109, 'total_tokens': 138})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(message_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "    (\"system\",\"You are the AI model providing good answer of any question in {laguage}\"),\n",
    "     (\"user\",\"{user_question}\")\n",
    "    ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ChatPromptValue' object has no attribute 'invoke'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m prompt\u001b[38;5;241m=\u001b[39m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlaguage\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHindi\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_question\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwho are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n",
      "File \u001b[1;32mf:\\Generative_AI\\Langchain Basic\\Lanchain_Basic\\lanchain_basic\\lib\\site-packages\\pydantic\\main.py:891\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    890\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 891\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ChatPromptValue' object has no attribute 'invoke'"
     ]
    }
   ],
   "source": [
    "prompt=prompt.invoke({\"laguage\":\"Hindi\",\"user_question\":\"who are you?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['laguage', 'user_question'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['laguage'], input_types={}, partial_variables={}, template='You are the AI model providing good answer of any question in {laguage}'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['user_question'], input_types={}, partial_variables={}, template='{user_question}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm.invoke()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='à¤œà¤¨à¤°à¥‡à¤Ÿà¤¿à¤µ à¤à¤†à¤ˆ à¤à¤• à¤ªà¥à¤°à¤•à¤¾à¤° à¤•à¤¾ à¤†à¤°à¥à¤Ÿà¤¿à¤«à¤¿à¤¶à¤¿à¤¯à¤² à¤‡à¤‚à¤Ÿà¥‡à¤²à¤¿à¤œà¥‡à¤‚à¤¸ (AI) à¤¹à¥ˆ à¤œà¥‹ à¤¨à¤ˆ à¤¸à¤¾à¤®à¤—à¥à¤°à¥€ à¤¬à¤¨à¤¾ à¤¸à¤•à¤¤à¤¾ à¤¹à¥ˆà¥¤ \\n\\nà¤¯à¤¹ à¤¸à¤¾à¤®à¤—à¥à¤°à¥€ à¤Ÿà¥‡à¤•à¥à¤¸à¥à¤Ÿ, à¤šà¤¿à¤¤à¥à¤°, à¤¸à¤‚à¤—à¥€à¤¤, à¤µà¥€à¤¡à¤¿à¤¯à¥‹, à¤•à¥‹à¤¡ à¤”à¤° à¤…à¤¨à¥à¤¯ à¤•à¤ˆ à¤°à¥‚à¤ªà¥‹à¤‚ à¤®à¥‡à¤‚ à¤¹à¥‹ à¤¸à¤•à¤¤à¥€ à¤¹à¥ˆà¥¤ \\n\\nà¤œà¤¨à¤°à¥‡à¤Ÿà¤¿à¤µ à¤à¤†à¤ˆ à¤®à¥‰à¤¡à¤² à¤¬à¥œà¥‡ à¤¡à¥‡à¤Ÿà¤¾à¤¸à¥‡à¤Ÿ à¤ªà¤° à¤ªà¥à¤°à¤¶à¤¿à¤•à¥à¤·à¤¿à¤¤ à¤¹à¥‹à¤¤à¥‡ à¤¹à¥ˆà¤‚, à¤œà¤¿à¤¸à¤¸à¥‡ à¤µà¥‡ à¤ªà¥ˆà¤Ÿà¤°à¥à¤¨ à¤”à¤° à¤¸à¤‚à¤°à¤šà¤¨à¤¾à¤“à¤‚ à¤•à¥‹ à¤¸à¥€à¤–à¤¤à¥‡ à¤¹à¥ˆà¤‚ à¤”à¤° à¤¨à¤ˆ à¤¸à¤¾à¤®à¤—à¥à¤°à¥€ à¤‰à¤¤à¥à¤ªà¤¨à¥à¤¨ à¤•à¤°à¤¨à¥‡ à¤•à¥‡ à¤²à¤¿à¤ à¤‰à¤¨à¤•à¤¾ à¤‰à¤ªà¤¯à¥‹à¤— à¤•à¤°à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤\\n\\n**à¤‰à¤¦à¤¾à¤¹à¤°à¤£:**\\n\\n* **à¤Ÿà¥‡à¤•à¥à¤¸à¥à¤Ÿ à¤œà¤¨à¤°à¥‡à¤Ÿà¤¿à¤µ à¤à¤†à¤ˆ:** ChatGPT, Bard à¤œà¥ˆà¤¸à¥‡ à¤®à¥‰à¤¡à¤² à¤œà¥‹ à¤•à¤¹à¤¾à¤¨à¤¿à¤¯à¤¾à¤, à¤•à¤µà¤¿à¤¤à¤¾à¤à¤, à¤²à¥‡à¤– à¤”à¤° à¤¸à¤‚à¤µà¤¾à¤¦ à¤²à¤¿à¤– à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤\\n* **à¤‡à¤®à¥‡à¤œ à¤œà¤¨à¤°à¥‡à¤Ÿà¤¿à¤µ à¤à¤†à¤ˆ:** DALL-E 2, Stable Diffusion à¤œà¥ˆà¤¸à¥‡ à¤®à¥‰à¤¡à¤² à¤œà¥‹ à¤ªà¤¾à¤  à¤•à¥‡ à¤†à¤§à¤¾à¤° à¤ªà¤° à¤šà¤¿à¤¤à¥à¤° à¤¬à¤¨à¤¾ à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤\\n* **à¤®à¥à¤¯à¥‚à¤œà¤¿à¤• à¤œà¤¨à¤°à¥‡à¤Ÿà¤¿à¤µ à¤à¤†à¤ˆ:** Jukebox, Amper Music à¤œà¥ˆà¤¸à¥‡ à¤®à¥‰à¤¡à¤² à¤œà¥‹ à¤¨à¤ à¤¸à¤‚à¤—à¥€à¤¤ à¤Ÿà¥à¤•à¥œà¥‡ à¤¬à¤¨à¤¾ à¤¸à¤•à¤¤à¥‡ à¤¹à¥ˆà¤‚à¥¤\\n\\n**à¤œà¤¨à¤°à¥‡à¤Ÿà¤¿à¤µ à¤à¤†à¤ˆ à¤•à¥‡ à¤‰à¤ªà¤¯à¥‹à¤—:**\\n\\n* **à¤•à¤²à¤¾ à¤”à¤° à¤°à¤šà¤¨à¤¾à¤¤à¥à¤®à¤•à¤¤à¤¾:** à¤•à¤²à¤¾à¤•à¤¾à¤°à¥‹à¤‚ à¤”à¤° à¤²à¥‡à¤–à¤•à¥‹à¤‚ à¤•à¥‹ à¤¨à¤ˆ à¤°à¤šà¤¨à¤¾à¤à¤ à¤¬à¤¨à¤¾à¤¨à¥‡ à¤®à¥‡à¤‚ à¤®à¤¦à¤¦ à¤•à¤°à¤¨à¤¾à¥¤\\n* **à¤µà¤¿à¤ªà¤£à¤¨ à¤”à¤° à¤µà¤¿à¤œà¥à¤žà¤¾à¤ªà¤¨:** à¤†à¤•à¤°à¥à¤·à¤• à¤¸à¤¾à¤®à¤—à¥à¤°à¥€ à¤¬à¤¨à¤¾à¤¨à¥‡ à¤”à¤° à¤²à¤•à¥à¤·à¤¿à¤¤ à¤¦à¤°à¥à¤¶à¤•à¥‹à¤‚ à¤¤à¤• à¤ªà¤¹à¥à¤à¤šà¤¨à¥‡ à¤®à¥‡à¤‚ à¤®à¤¦à¤¦ à¤•à¤°à¤¨à¤¾à¥¤\\n* **à¤¶à¤¿à¤•à¥à¤·à¤¾:** à¤›à¤¾à¤¤à¥à¤°à¥‹à¤‚ à¤•à¥‹ à¤¸à¥€à¤–à¤¨à¥‡ à¤”à¤° à¤…à¤­à¥à¤¯à¤¾à¤¸ à¤•à¤°à¤¨à¥‡ à¤®à¥‡à¤‚ à¤®à¤¦à¤¦ à¤•à¤°à¤¨à¤¾à¥¤\\n* **à¤‰à¤¦à¥à¤¯à¥‹à¤—:** à¤‰à¤¤à¥à¤ªà¤¾à¤¦ à¤¡à¤¿à¤œà¤¾à¤‡à¤¨, à¤—à¥à¤°à¤¾à¤¹à¤• à¤¸à¥‡à¤µà¤¾ à¤”à¤° à¤…à¤¨à¥à¤¯ à¤•à¤¾à¤°à¥à¤¯à¥‹à¤‚ à¤•à¥‹ à¤¸à¥à¤µà¤šà¤¾à¤²à¤¿à¤¤ à¤•à¤°à¤¨à¤¾à¥¤\\n\\n\\nà¤œà¤¨à¤°à¥‡à¤Ÿà¤¿à¤µ à¤à¤†à¤ˆ à¤à¤• à¤¤à¥‡à¤œà¥€ à¤¸à¥‡ à¤µà¤¿à¤•à¤¸à¤¿à¤¤ à¤¹à¥‹ à¤°à¤¹à¤¾ à¤•à¥à¤·à¥‡à¤¤à¥à¤° à¤¹à¥ˆ à¤œà¤¿à¤¸à¤•à¥‡ à¤•à¤ˆ à¤¸à¤‚à¤­à¤¾à¤µà¤¿à¤¤ à¤…à¤¨à¥à¤ªà¥à¤°à¤¯à¥‹à¤— à¤¹à¥ˆà¤‚à¥¤\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 392, 'prompt_tokens': 27, 'total_tokens': 419, 'completion_time': 0.712727273, 'prompt_time': 0.002130082, 'queue_time': 0.233622506, 'total_time': 0.714857355}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-1d0d7eae-3aeb-40cb-b795-788274900aa3-0', usage_metadata={'input_tokens': 27, 'output_tokens': 392, 'total_tokens': 419})"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"laguage\":\"Hindi\",\"user_question\":\"what is generative AI?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"you are very bad AI model providing very dump answer in {language}\"),\n",
    "    MessagesPlaceholder(variable_name=\"question\"),\n",
    "\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain=prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Â¡Hola! \\n\\nGenerative AI es como un artista muy inteligente que puede crear cosas nuevas. \\n\\nImagina que le dices a un artista \"dibuja un gato con sombrero\" y Ã©l lo hace. \\n\\nEl AI generativo puede hacer lo mismo, pero con texto, imÃ¡genes, mÃºsica, Â¡y hasta cÃ³digo! \\n\\nEs como si tuviera un montÃ³n de ideas en su cabeza y pudiera convertirlas en realidad. \\n\\nÂ¿Te parece interesante? \\n\\n\\nLet me know if you have any other questions! \\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 111, 'prompt_tokens': 25, 'total_tokens': 136, 'completion_time': 0.201818182, 'prompt_time': 0.002132466, 'queue_time': 0.232217247, 'total_time': 0.203950648}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d5e03238-5cdb-453e-ab8b-c8015a5155a8-0', usage_metadata={'input_tokens': 25, 'output_tokens': 111, 'total_tokens': 136})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke ({\"question\":[HumanMessage(content=\"what is generative AI\")],\"language\":\"spain\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2=ChatPromptTemplate.from_template(\"You are very tallented AI producing very good answer {question} in {language}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['hindi', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['hindi', 'question'], input_types={}, partial_variables={}, template='You are very tallented AI producing very good answer {question} in {hindi}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_1=prompt_2|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='## à¤­à¤¾à¤°à¤¤: à¤à¤• à¤µà¤¿à¤¸à¥à¤¤à¥ƒà¤¤ à¤ªà¤°à¤¿à¤šà¤¯ \\n\\nà¤­à¤¾à¤°à¤¤, à¤à¤• à¤ªà¥à¤°à¤¾à¤šà¥€à¤¨ à¤”à¤° à¤¸à¤®à¥ƒà¤¦à¥à¤§ à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿ à¤µà¤¾à¤²à¤¾ à¤¦à¥‡à¤¶, à¤¦à¤•à¥à¤·à¤¿à¤£ à¤à¤¶à¤¿à¤¯à¤¾ à¤®à¥‡à¤‚ à¤¸à¥à¤¥à¤¿à¤¤ à¤¹à¥ˆà¥¤ à¤¯à¤¹ à¤¦à¥à¤¨à¤¿à¤¯à¤¾ à¤•à¤¾ à¤¸à¤¾à¤¤à¤µà¤¾à¤‚ à¤¸à¤¬à¤¸à¥‡ à¤¬à¤¡à¤¼à¤¾ à¤¦à¥‡à¤¶ à¤¹à¥ˆ à¤”à¤° à¤¦à¥à¤¨à¤¿à¤¯à¤¾ à¤•à¥€ à¤¸à¤¬à¤¸à¥‡ à¤¬à¤¡à¤¼à¥€ à¤²à¥‹à¤•à¤¤à¤‚à¤¤à¥à¤°à¥‹à¤‚ à¤®à¥‡à¤‚ à¤¸à¥‡ à¤à¤• à¤¹à¥ˆà¥¤ \\n\\n**à¤­à¥Œà¤—à¥‹à¤²à¤¿à¤• à¤µà¤¿à¤µà¤¿à¤§à¤¤à¤¾:**\\n\\nà¤­à¤¾à¤°à¤¤ à¤à¤• à¤­à¥Œà¤—à¥‹à¤²à¤¿à¤• à¤°à¥‚à¤ª à¤¸à¥‡ à¤µà¤¿à¤µà¤¿à¤§ à¤¦à¥‡à¤¶ à¤¹à¥ˆ, à¤œà¤¿à¤¸à¤®à¥‡à¤‚ à¤¹à¤¿à¤®à¤¾à¤²à¤¯ à¤ªà¤°à¥à¤µà¤¤ à¤¶à¥à¤°à¥ƒà¤‚à¤–à¤²à¤¾ à¤¸à¥‡ à¤²à¥‡à¤•à¤° à¤—à¤‚à¤—à¤¾ à¤”à¤° à¤¬à¥à¤°à¤¹à¥à¤®à¤ªà¥à¤¤à¥à¤° à¤¨à¤¦à¤¿à¤¯à¥‹à¤‚ à¤•à¥‡ à¤®à¥ˆà¤¦à¤¾à¤¨à¥‹à¤‚ à¤¤à¤•, à¤¸à¤®à¥à¤¦à¥à¤° à¤¤à¤Ÿà¥‹à¤‚ à¤¸à¥‡ à¤²à¥‡à¤•à¤° à¤°à¥‡à¤—à¤¿à¤¸à¥à¤¤à¤¾à¤¨à¥‹à¤‚ à¤¤à¤•, à¤µà¤¿à¤­à¤¿à¤¨à¥à¤¨ à¤ªà¥à¤°à¤•à¤¾à¤° à¤•à¥‡ à¤ªà¤°à¤¿à¤¦à¥ƒà¤¶à¥à¤¯ à¤¹à¥ˆà¤‚à¥¤ \\n\\n* **à¤¹à¤¿à¤®à¤¾à¤²à¤¯:** à¤­à¤¾à¤°à¤¤ à¤•à¥‡ à¤‰à¤¤à¥à¤¤à¤°à¥€ à¤­à¤¾à¤— à¤®à¥‡à¤‚ à¤¸à¥à¤¥à¤¿à¤¤, à¤¯à¤¹ à¤¦à¥à¤¨à¤¿à¤¯à¤¾ à¤•à¥€ à¤¸à¤¬à¤¸à¥‡ à¤Šà¤à¤šà¥€ à¤ªà¤°à¥à¤µà¤¤ à¤¶à¥à¤°à¥ƒà¤‚à¤–à¤²à¤¾ à¤¹à¥ˆ, à¤œà¤¿à¤¸à¤®à¥‡à¤‚ à¤®à¤¾à¤‰à¤‚à¤Ÿ à¤à¤µà¤°à¥‡à¤¸à¥à¤Ÿ à¤­à¥€ à¤¶à¤¾à¤®à¤¿à¤² à¤¹à¥ˆà¥¤ \\n* **à¤—à¤‚à¤—à¤¾ à¤”à¤° à¤¬à¥à¤°à¤¹à¥à¤®à¤ªà¥à¤¤à¥à¤° à¤¨à¤¦à¤¿à¤¯à¤¾à¤:** à¤­à¤¾à¤°à¤¤ à¤•à¥€ à¤¸à¤¬à¤¸à¥‡ à¤®à¤¹à¤¤à¥à¤µà¤ªà¥‚à¤°à¥à¤£ à¤¨à¤¦à¤¿à¤¯à¤¾à¤ à¤¹à¥ˆà¤‚, à¤œà¥‹ à¤•à¥ƒà¤·à¤¿ à¤”à¤° à¤œà¥€à¤µà¤¨ à¤•à¥‡ à¤²à¤¿à¤ à¤®à¤¹à¤¤à¥à¤µà¤ªà¥‚à¤°à¥à¤£ à¤¹à¥ˆà¤‚à¥¤ \\n* **à¤¸à¤®à¥à¤¦à¥à¤° à¤¤à¤Ÿ:** à¤­à¤¾à¤°à¤¤ à¤•à¥‡ à¤¦à¤•à¥à¤·à¤¿à¤£ à¤”à¤° à¤ªà¤¶à¥à¤šà¤¿à¤® à¤¤à¤Ÿà¥‹à¤‚ à¤ªà¤° à¤²à¤‚à¤¬à¥‡ à¤¸à¤®à¥à¤¦à¥à¤° à¤¤à¤Ÿ à¤¹à¥ˆà¤‚, à¤œà¥‹ à¤ªà¤°à¥à¤¯à¤Ÿà¤¨ à¤•à¥‡ à¤²à¤¿à¤ à¤²à¥‹à¤•à¤ªà¥à¤°à¤¿à¤¯ à¤¹à¥ˆà¤‚à¥¤ \\n* **à¤°à¥‡à¤—à¤¿à¤¸à¥à¤¤à¤¾à¤¨:** à¤­à¤¾à¤°à¤¤ à¤•à¥‡ à¤ªà¤¶à¥à¤šà¤¿à¤®à¥€ à¤­à¤¾à¤— à¤®à¥‡à¤‚ à¤¥à¤¾à¤° à¤°à¥‡à¤—à¤¿à¤¸à¥à¤¤à¤¾à¤¨ à¤¸à¥à¤¥à¤¿à¤¤ à¤¹à¥ˆ, à¤œà¥‹ à¤à¤• à¤¶à¥à¤·à¥à¤• à¤”à¤° à¤°à¥‡à¤¤à¥€à¤²à¤¾ à¤•à¥à¤·à¥‡à¤¤à¥à¤° à¤¹à¥ˆà¥¤\\n\\n**à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿ à¤”à¤° à¤‡à¤¤à¤¿à¤¹à¤¾à¤¸:**\\n\\nà¤­à¤¾à¤°à¤¤ à¤•à¥€ à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿ à¤ªà¥à¤°à¤¾à¤šà¥€à¤¨ à¤”à¤° à¤¸à¤®à¥ƒà¤¦à¥à¤§ à¤¹à¥ˆ, à¤œà¤¿à¤¸à¤®à¥‡à¤‚ à¤µà¤¿à¤­à¤¿à¤¨à¥à¤¨ à¤§à¤°à¥à¤®à¥‹à¤‚, à¤­à¤¾à¤·à¤¾à¤“à¤‚ à¤”à¤° à¤ªà¤°à¤‚à¤ªà¤°à¤¾à¤“à¤‚ à¤•à¤¾ à¤®à¤¿à¤¶à¥à¤°à¤£ à¤¹à¥ˆà¥¤ \\n\\n* **à¤§à¤°à¥à¤®:** à¤­à¤¾à¤°à¤¤ à¤®à¥‡à¤‚ à¤¹à¤¿à¤‚à¤¦à¥‚ à¤§à¤°à¥à¤®, à¤‡à¤¸à¥à¤²à¤¾à¤®, à¤¸à¤¿à¤– à¤§à¤°à¥à¤®, à¤¬à¥Œà¤¦à¥à¤§ à¤§à¤°à¥à¤® à¤”à¤° à¤ˆà¤¸à¤¾à¤ˆ à¤§à¤°à¥à¤® à¤œà¥ˆà¤¸à¥‡ à¤µà¤¿à¤­à¤¿à¤¨à¥à¤¨ à¤§à¤°à¥à¤®à¥‹à¤‚ à¤•à¤¾ à¤ªà¤¾à¤²à¤¨ à¤•à¤¿à¤¯à¤¾ à¤œà¤¾à¤¤à¤¾ à¤¹à¥ˆà¥¤ \\n* **à¤­à¤¾à¤·à¤¾à¤à¤:** à¤­à¤¾à¤°à¤¤ à¤®à¥‡à¤‚ 22 à¤†à¤§à¤¿à¤•à¤¾à¤°à¤¿à¤• à¤­à¤¾à¤·à¤¾à¤à¤ à¤¹à¥ˆà¤‚, à¤”à¤° à¤•à¤ˆ à¤…à¤¨à¥à¤¯ à¤•à¥à¤·à¥‡à¤¤à¥à¤°à¥€à¤¯ à¤­à¤¾à¤·à¤¾à¤à¤ à¤¬à¥‹à¤²à¥€ à¤œà¤¾à¤¤à¥€ à¤¹à¥ˆà¤‚à¥¤ \\n* **à¤ªà¤°à¤‚à¤ªà¤°à¤¾à¤à¤:** à¤­à¤¾à¤°à¤¤ à¤®à¥‡à¤‚ à¤µà¤¿à¤­à¤¿à¤¨à¥à¤¨ à¤ªà¥à¤°à¤•à¤¾à¤° à¤•à¥€ à¤ªà¤°à¤‚à¤ªà¤°à¤¾à¤à¤ à¤¹à¥ˆà¤‚, à¤œà¥ˆà¤¸à¥‡ à¤¤à¥à¤¯à¥‹à¤¹à¤¾à¤°, à¤¶à¤¾à¤¦à¥€ à¤”à¤° à¤§à¤¾à¤°à¥à¤®à¤¿à¤• à¤…à¤¨à¥à¤·à¥à¤ à¤¾à¤¨à¥¤\\n\\n**à¤†à¤°à¥à¤¥à¤¿à¤• à¤µà¤¿à¤•à¤¾à¤¸:**\\n\\nà¤­à¤¾à¤°à¤¤ à¤à¤• à¤¤à¥‡à¤œà¥€ à¤¸à¥‡ à¤µà¤¿à¤•à¤¾à¤¸à¤¶à¥€à¤² à¤…à¤°à¥à¤¥à¤µà¥à¤¯à¤µà¤¸à¥à¤¥à¤¾ à¤¹à¥ˆ, à¤œà¥‹ à¤¸à¥‚à¤šà¤¨à¤¾ à¤ªà¥à¤°à¥Œà¤¦à¥à¤¯à¥‹à¤—à¤¿à¤•à¥€, à¤¸à¥‡à¤µà¤¾ à¤•à¥à¤·à¥‡à¤¤à¥à¤° à¤”à¤° à¤•à¥ƒà¤·à¤¿ à¤®à¥‡à¤‚ à¤®à¤œà¤¬à¥‚à¤¤ à¤¹à¥ˆà¥¤ \\n\\n* **IT à¤‰à¤¦à¥à¤¯à¥‹à¤—:** à¤­à¤¾à¤°à¤¤ à¤®à¥‡à¤‚ à¤à¤• à¤¬à¤¡à¤¼à¤¾ IT à¤‰à¤¦à¥à¤¯à¥‹à¤— à¤¹à¥ˆ, à¤œà¥‹ à¤¦à¥à¤¨à¤¿à¤¯à¤¾ à¤­à¤° à¤®à¥‡à¤‚ à¤¸à¥‡à¤µà¤¾à¤à¤ à¤ªà¥à¤°à¤¦à¤¾à¤¨ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆà¥¤ \\n* **à¤¸à¥‡à¤µà¤¾ à¤•à¥à¤·à¥‡à¤¤à¥à¤°:** à¤­à¤¾à¤°à¤¤ à¤•à¤¾ à¤¸à¥‡à¤µà¤¾ à¤•à¥à¤·à¥‡à¤¤à¥à¤° à¤¤à¥‡à¤œà¥€ à¤¸à¥‡ à¤¬à¤¢à¤¼ à¤°à¤¹à¤¾ à¤¹à¥ˆ, à¤œà¤¿à¤¸à¤®à¥‡à¤‚ à¤¬à¥ˆà¤‚à¤•à¤¿à¤‚à¤—, à¤µà¤¿à¤¤à¥à¤¤ à¤”à¤° à¤ªà¤°à¥à¤¯à¤Ÿà¤¨ à¤¶à¤¾à¤®à¤¿à¤² à¤¹à¥ˆà¤‚à¥¤ \\n* **à¤•à¥ƒà¤·à¤¿:** à¤­à¤¾à¤°à¤¤ à¤®à¥‡à¤‚ à¤•à¥ƒà¤·à¤¿ à¤à¤• à¤®à¤¹à¤¤à¥à¤µà¤ªà¥‚à¤°à¥à¤£ à¤‰à¤¦à¥à¤¯à¥‹à¤— à¤¹à¥ˆ, à¤œà¥‹ à¤¦à¥‡à¤¶ à¤•à¥€ à¤†à¤¬à¤¾à¤¦à¥€ à¤•à¥‡ à¤à¤• à¤¬à¤¡à¤¼à¥‡ à¤¹à¤¿à¤¸à¥à¤¸à¥‡ à¤•à¥‹ à¤°à¥‹à¤œà¤—à¤¾à¤° à¤ªà¥à¤°à¤¦à¤¾à¤¨ à¤•à¤°à¤¤à¤¾ à¤¹à¥ˆà¥¤\\n\\n**à¤šà¥à¤¨à¥Œà¤¤à¤¿à¤¯à¤¾à¤:**\\n\\nà¤­à¤¾à¤°à¤¤ à¤•à¥‡ à¤¸à¤¾à¤®à¤¨à¥‡ à¤•à¤ˆ à¤šà¥à¤¨à¥Œà¤¤à¤¿à¤¯à¤¾à¤ à¤¹à¥ˆà¤‚, à¤œà¥ˆà¤¸à¥‡ à¤—à¤°à¥€à¤¬à¥€, à¤¬à¥‡à¤°à¥‹à¤œà¤—à¤¾à¤°à¥€, à¤¶à¤¿à¤•à¥à¤·à¤¾ à¤”à¤° à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯ à¤¸à¥‡à¤µà¤¾à¤“à¤‚ à¤®à¥‡à¤‚ à¤¸à¥à¤§à¤¾à¤°, à¤”à¤° à¤ªà¤°à¥à¤¯à¤¾à¤µà¤°à¤£ à¤¸à¤‚à¤°à¤•à¥à¤·à¤£à¥¤ \\n\\n**à¤­à¤µà¤¿à¤·à¥à¤¯:**\\n\\nà¤­à¤¾à¤°à¤¤ à¤à¤• à¤‰à¤œà¥à¤œà¤µà¤² à¤­à¤µà¤¿à¤·à¥à¤¯ à¤•à¥€ à¤“à¤° à¤¬à¤¢à¤¼ à¤°à¤¹à¤¾ à¤¹à¥ˆ, à¤”à¤° à¤‡à¤¸à¤•à¥‡ à¤µà¤¿à¤•à¤¾à¤¸ à¤•à¥€ à¤•à¥à¤·à¤®à¤¤à¤¾ à¤…à¤¸à¥€à¤® à¤¹à¥ˆà¥¤ \\n\\n\\nà¤¯à¤¹ à¤­à¤¾à¤°à¤¤ à¤•à¤¾ à¤à¤• à¤¸à¤‚à¤•à¥à¤·à¤¿à¤ªà¥à¤¤ à¤ªà¤°à¤¿à¤šà¤¯ à¤¹à¥ˆà¥¤ \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 733, 'prompt_tokens': 25, 'total_tokens': 758, 'completion_time': 1.332727273, 'prompt_time': 0.002152538, 'queue_time': 0.23059501699999999, 'total_time': 1.334879811}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-d0be07e3-2258-4c2e-98a7-f9114a164495-0', usage_metadata={'input_tokens': 25, 'output_tokens': 733, 'total_tokens': 758})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_1.invoke({\"question\":\"explain INDIA in detail\",\"language\":\"Hindi\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatHistory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "store={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_with_history = RunnableWithMessageHistory(\n",
    "    llm,\n",
    "    get_session_history,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"ABC\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1=[HumanMessage(content=\"Hi, I am Abhijeet\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=chat_with_history.invoke(prompt,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Abhijeet, it's nice to meet you! ðŸ‘‹\\n\\nWhat can I do for you today? ðŸ˜Š\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 15, 'total_tokens': 41, 'completion_time': 0.047272727, 'prompt_time': 0.001912047, 'queue_time': 0.235639542, 'total_time': 0.049184774}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b9cd53ae-99e2-4fe8-9a6c-9f0e82b9b49c-0', usage_metadata={'input_tokens': 15, 'output_tokens': 26, 'total_tokens': 41})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2=[HumanMessage(content=\"Hi,who i am\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2=chat_with_history.invoke(prompt_2,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You are Abhijeet!  \\n\\nIs there anything else you'd like to know about yourself, or would you like to talk about something else? ðŸ˜Š  \\n\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_2.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
